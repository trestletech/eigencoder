---
title: "EigenCoders"
author: "Jeff Allen"
date: "March 8, 2016"
output: 
  html_document: 
    keep_md: yes
---

There are a lot of stereotypes in the programming community. "Swift is used by a bunch of bearded hipsters." "C++ is for old people." "No one likes coding in Java." Well it turns out that some of these might be true.

## Approach

[GitHub](https://github.com) is likely the most popular open-source hosting platform in use today. GitHub has many open-source repositories for code written in wide variety of languages. They also provide ["trending" pages](https://github.com/trending/go?since=monthly) which show you repositories in a particular language that are particularly popular right now.

These popular repositories also include the profile pictures of some of the most prolific committers on these projects. Meaning that we can easily get a few dozen profile pictures of some of the busiest contributors to popular projects for any given language. 

We also have access to a neat resource from Microsoft's Project Oxford called the "[Face API](https://www.projectoxford.ai/face)" which, among other things, can detect a face in a given image and estimate some properties about the face. Is the subject smiling? What gender and age are they? Do they have facial hair?

Combined, we can get an estimate of some interesting properties about the profile pictures of programmers who are working in various languages. Let's get started!

<div class="alert alert-warning">It should be noted that this is super non-scientific. Who knows how accurate the Face API is or how accurately a user's GitHub profile picture maps to any aspect of their personality/identity. It's also unclear whether the most prolific contributors to popular repositories accurately represent a community. Also, small sample sizes. Etc., etc.</div>

All code used in this post is available here: [https://github.com/trestletech/eigencoder](https://github.com/trestletech/eigencoder)

## Data

```{r gathering, cache=TRUE,message=FALSE, warning=FALSE, echo=FALSE}
library(rvest)

languages <- c("ruby", "r", "javascript", "java", "html", "go", "cpp", "c", "python", "php", "perl", "swift", "csharp")

source("betaface.R")

#TODO: lookup name from GitHub to help detect gender

get_profiles <- function(lang){
  ht <- read_html(paste0("https://github.com/trending/", lang, "?since=monthly"))
  contribs <- ht %>% 
    html_nodes(".repo-list-item .repo-list-meta .avatar")
  
  authors <- contribs %>% html_attr("alt")  
  authors <- gsub("^@", "", authors)
  imgs <- contribs %>% html_attr("src")
  imgs <- gsub("s=40", "s=420", imgs)
  
  names(imgs) <- authors
  imgs
}

results <- list()
for (langInd in 1:length(languages)){
  lang <- languages[langInd]
  message("Processing ", lang, "...")
  prof <- get_profiles(lang)
  
  df <- data.frame(
    username=character(0), 
    smile=numeric(0),
    gender=character(0),
    age=numeric(0),
    mustache=numeric(0),
    beard=numeric(0),
    sideburns=numeric(0)
  )
  for (i in 1:length(prof)){
    tryCatch({
      attrs <- cached_msface(prof[[i]], ms_key)
      df <- rbind(df, data.frame(
                  username=names(prof)[i],
                  smile=attrs$smile,
                  gender=attrs$gender,
                  age=attrs$age,
                  mustache=attrs$facialHair$moustache,
                  beard=attrs$facialHair$beard,
                  sideburns=attrs$facialHair$sideburns
              ))
    }, error = function(e){
      df <- rbind(df, data.frame(
                  username=names(prof)[i],
                  smile=NA,
                  gender=NA,
                  age=NA,
                  mustache=NA,
                  beard=NA,
                  sideburns=NA))
    })
  }
  results[[langInd]] <- df
  saveRDS(results, "results.Rds")
}
```

```{r unique, echo=FALSE}
# We can exclude redundant usernames in each programming language.
names(results) <- languages
saveRDS(results, "results.Rds")

# Filter to only include unique users
# TODO: do this before looking up their face API redundantly
results <- lapply(results, function(x){
  unique(x)
})
saveRDS(results, "unique-results.Rds")
```

GitHub lists 25 repositories on its trending page and shows the top 5 committers for each. Some projects don't have 5 contributors, so fewer are shown. We remove duplicated usernames then send each of these profile pictures (up to 125 per language) to be analyzed by the Face API. Of course, not all pictures have (detectable) faces in them.

In total, we get the following:

```{r, echo=FALSE, results='asis'}
df <- data.frame(Lang=languages, FacesDetected=numeric(length(languages)))
for (i in 1:length(languages)){
  df[i,2] <- nrow(results[[i]])
}

knitr::kable(df)
```


## Gender

One of the properties returned by the Face API is a prediction of the gender of the subject of the photo. The results are pretty discouraging for anyone who's not a chauvinist...

```{r gender, warning=FALSE, echo=FALSE, message=FALSE}
library(dplyr)

gender <- lapply(names(results), function(nm) {
  results[[nm]] %>%
    count(gender) %>% 
    mutate(prop = prop.table(n)) %>% 
    mutate(language = nm) %>% 
    rename(ratio = prop) %>% 
    select(language, gender, n, ratio)
})
gender <- bind_rows(gender) %>% 
  arrange(desc(gender), desc(ratio))

library(plotly)
plot_ly(gender, x=language, y=ratio, type="bar", color=gender) %>% 
  layout(barmode="stack")
```

## Age

Age is an interesting trend. Some people assume that "old-school" languages are only used by old people and that new, trendy languages are used by hipsters. It turns out that's not always true; Java, for instance, has the *lowest* median age.

```{r age, warning=FALSE, echo=FALSE}
listToDF <- function(lst, name="val"){
  df <- NULL
  for (i in 1:length(lst)){
    li <- lst[[i]]
    f <- data.frame(language=rep(names(lst)[i], length(li)), 
                     val=li, stringsAsFactors = FALSE)
    df <- bind_rows(df, f)
  }
  colnames(df)[2] <- name
  df
}

listToDensity <- function(lst, title="", xlab="x", ...){
  dens <- lapply(lst, function(li){
    breaks <- seq(from=min(li), to=max(li), length.out=6)
    cu <- cut(li, breaks, right=FALSE, labels=breaks[-1])
    
    # Prepend 0
    ar <- c(0, table(cu))
    names(ar)[1] <- "0"
    
    ar
  })
  df <- data.frame(
    x = unlist(lapply(dens, function(x){as.numeric(names(x))})),
    y = unlist(lapply(dens, as.numeric)),
    lang = rep(names(dens), each = length(dens[[1]]))
  )
  
  plot_ly(df, x=x, y=y, color=lang) %>% 
    layout(title=title, xaxis=list(title=xlab), yaxis=list(title="Ratio"), autosize=FALSE, ...)
}

listToBar <- function(lst, fun, title="", ylab="Average"){
  avg <- sapply(lst, fun)  
  df <- as.data.frame(avg)
  df$language <- rownames(df)
  
  df <- df %>% arrange(desc(avg))
  
  plot_ly(df, x=language, y=avg, type="bar") %>% 
    layout(title=title, yaxis=list(title=ylab), autosize=TRUE)
}

ages <- lapply(results, "[[", "age")

library(shiny)
tabsetPanel(
  tabPanel("Barplot", print(listToBar(ages, median, "Median Age of Programmers by Language", "Median Age"))),
  tabPanel("Density",  print(listToDensity(ages, "Age of Programmers by Language", "Age")))
)
```

## Smiles

Every programmer has a language that makes them miserable. So miserable, perhaps, that you can't even muster a smile for your GitHub profile picture. 

The Face API returns a score from 0 to 1 approximating the amount that you're smiling. Programmers using certain languages seem happier than others. Maybe R programmers are just smiling about the [crazy market for data scientists](https://www.oreilly.com/ideas/2015-data-science-salary-survey) in this economy...

```{r smiles, warning=FALSE, echo=FALSE}
smiles <- lapply(results, "[[", "smile")

tabsetPanel(
  tabPanel("Barplot", print(listToBar(smiles, mean, "Mean Smiliness of Programmers by Language", "Mean Smile Score"))),
  tabPanel("Density",  print(listToDensity(smiles, "Smiliness of Programmers by Language", "Smile Score")))
)
```

## Facial Hair

If you've been coding for any length of time, you've met at least one mustached fellow riding a fixie and wearing skinny jeans who won't stop talking about Swift. Turns out that's a real stereotype.

I did not normalize for gender here.

```{r hair, warning=FALSE, echo=FALSE}
mustache <- lapply(results, "[[", "mustache")
beard <- lapply(results, "[[", "beard")
sideburns <- lapply(results, "[[", "sideburns")

# Facial Hair
facialHair <- list()
for (i in 1:length(mustache)){
  facialHair[[i]] <- mustache[[i]] + beard[[i]] + sideburns[[i]]
}
names(facialHair) <- languages

tabsetPanel(
  tabPanel("Barplot", print(listToBar(facialHair, mean, "Average Facial Hair by Language", "Facial Hair"))),
  tabPanel("Density",  print(listToDensity(facialHair, "Facial Hair by Language", "Facial Hair")))
)
```

Or we can look at each facial hair property returned by the Face API individually.

```{r, warning=FALSE, echo=FALSE}
tabsetPanel(
  tabPanel("Mustache", print(listToDensity(mustache, "Mustaches by Language", "Mustaches"))),
  tabPanel("Beard", print(listToDensity(beard, "Beards by Language", "Beards"))),
  tabPanel("Sideburns", print(listToDensity(sideburns, "Sideburns by Language", "Sideburns")))
)
```

## Conclusion

I guess to grow a mustache if you want to contribute to a successful C++ project? 

In reality, you'd need a much larger sample size and some guarantees around the accuracy of the Face API before you could have any real confidence about the conclusions you draw from this data.
